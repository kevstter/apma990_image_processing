\chapter{Geodesic Active Contours}
\label{ch:gac}
The first segmentation model we review is the geodesic active contours (GAC) model from Caselles, Kimmel, and Sapiro \cite{caselles1997geodesic}. Their model of segmentation gives (near) automaticatic selection of an object or objects from an image once the initial contour $\C_0$ is prescribed. To get an active contour $\C = \C(t)$ with $\C(0) = \C_0$, they argued for the minimization of the energy 
\begin{align}
E_\mathrm{GAC}(\C) = \int^{L(\C)}_0 g\left( \abs{\nabla f } \right) \, ds,
\label{eq:egac}
\end{align}
where 
\begin{align*}
f&: \textrm{initial image},
\\
L(\C) &: \textrm{the length of the contour $\C$,} 
\\ 
g(\xi)&: \textrm{an edge indicator function}.
\end{align*}
The energy $E_\textrm{GAC}$ may be interpreted as a weighted arc length. If $g(\xi) = 1$, we would recognize $\int_\C  ds$ as standard Euclidean arc length. The idea is that by designing $g$ is be small near edges and large over homogeneous regions, one would expect the contour $\C$ to be drawn to and remain at object edges when minimizing $E_\textrm{GAC}$. As examples, one may set $g$ as 
\begin{align*}
g_1(\xi) 
= \frac{1}{1 + \alpha\xi^2},
\quad\text{or}\quad 
g_2(\xi) 
= \exp(-\beta\xi^2).
\end{align*}
Notice that as $\abs{\xi} \rightarrow \infty$, $g_1,g_2 \rightarrow 0$.  

In the next sections, we will derive the Euler-Lagrange equation and discuss its discretization for minimizing $\egac$. Numerical examples will demonstrate some of the strengths and weaknesses of this model. One notable weakness of this energy that we point to here is that by design we must be seeking a local minimum. Unfortunately, the global minimum of zero is obtained only when the contour contracts to a point and vanishes. We will revisit this issue when reviewing the numerical examples.


\section{Euler-Lagrange equation to the GAC model} 
A bit of setup and a quick review of vector calculus will go a long ways for this derivation. Let $\C: [0,1]\rightarrow \mathbf{R}^2$ be a parametrized curve, $\C = \C(p)$. We then relate the arc length element to the parameter $p$ as $ds = \abs{C'(p)} dp$. We also recognize the unit tangent vector, $\tang$, unit (inward) normal, $\normal$, and curvature, $\kappa$, as 
\begin{align*}
\tang 
= \frac{\C'}{\abs{\C'}},\quad 
\normal 
= \frac{ \tang '}{\abs{\tang'}},
\quad\text{and}\quad 
\kappa = \frac{ \abs{\tang'} }{ \abs{ \C' } },
\end{align*}
with the prime notation denoting differentiation w.r.t. $p$. We also assume $\C(0) = \C(1)$. 

Rewriting $\egac$ as 
\begin{align*}
\egac = \int^{L(\C)}_0 g \, ds 
= \int^1_0 g(\C) \abs{\C'(p)} \, dp ,
\end{align*} 
we can compute its first variation: 
\begin{align*}
\dd{}{\gamma} \int^1_0 g(\C + \gamma h) \abs{\C' + \gamma h'} \, dp \bigg\rvert_{\gamma = 0}
&=  \int^1_0 \nabla g(\C) \cdot h \abs{\C'} + g(\C) \frac{\C'}{\abs{\C'}} \cdot h' \,dp 
\\
&=\int^1_0 \nabla g(\C) \cdot h \abs{\C'} + g(\C) \tang \cdot h' \,dp 
\\
&=\int^1_0 \nabla g \cdot h \abs{\C'} - ( g \tang)' \cdot h \, dp
\\
&=\int^1_0 \nabla g \cdot h \abs{\C'} - (\nabla g \cdot \C')(\tang \cdot h) - g\tang ' \cdot h \, dp
\\
&=\int^1_0 \nabla g \cdot h \abs{\C'} - (\nabla g \cdot \tang \abs{\C'} )(\tang \cdot h) - g\abs{\tang'} \normal \cdot h \, dp
\\
&=\int^1_0 \big[ \nabla g  - (\nabla g \cdot \tang )\tang \big] \cdot h \abs{\C'} - g\kappa \abs{\C'} \normal \cdot h \, dp
\\
&=\int^1_0 \big[\nabla g \cdot \normal \normal \big] \cdot h \abs{\C'} - g\kappa  \normal \cdot h \abs{\C'} \, dp
\\
&=\int^1_0 \big[ \nabla g \cdot \normal - g\kappa \big] \normal  \cdot h \abs{\C'} \, dp.
\\ 
\end{align*}
This gives the gradient descent equation $\C_t = \left( g(\C) \kappa - \nabla g(\C) \cdot \normal \right) \normal $.
The level set formulation with level set function $\phi = \phi(x, t)$ is
\begin{align}
\begin{split} 
\phi_t 
&= \left(
g( \abs{\nabla I } ) \Div\left( \frac{\nabla \phi}{\abs{\nabla \phi}} \right)
	+  \nabla g(  \abs{\nabla I } )\cdot  \frac{\nabla \phi}{\abs{\nabla \phi}}
\right) \abs{ \nabla \phi }
\\
&= \abs{\nabla \phi} \Div\left( 
g(  \abs{\nabla I } ) \frac{\nabla \phi}{\abs{\nabla \phi}}
\right) .
\end{split}
\label{eq:gac_ls}
\end{align}

\section{Numerical discretization}
\label{sec:gac_num_disc}
To discretize \eqref{eq:gac_ls}, we use the semi-implicit Gauss-Seidel  numerical scheme proposed by Aubert and Vese \cite{aubert1997variational} and used to good effect by Chan and Vese with their ACWE model \cite{chan2001active} rather than using explicit forward Euler with second order centred differences as originally suggested\footnote{Although to be fair, it was suggested for ease of implementation as a proof of concept. For us, the same semi-implicit numerical scheme can and will be used again in \Cref{ch:acwe,ch:gcs} so it makes sense to give a complete presentation once and be able to reuse essentially the same code three times.} in \cite{caselles1997geodesic}.

Define the discrete differential operators: $D_x^+ u_{ij} = (u_{i+1,j} - u_{ij})/h$, $D^0_x = (u_{i+1,j} - u_{i-1,j})/(2h)$,
$D^-_x u_{ij} = (u_{ij} - u_{i-1,j})/h$, and similarly for $D^+_y, D^0_y, D^-_y$.  We will also let $\abs{D^0 \phi^n} = \sqrt{(D^0_x \phi^n_{ij})^2 + (D^0_y \phi^n_{ij})^2 } $ and let $\varepsilon > 0$ be a small regularization parameter. 
Then discretize \eqref{eq:gac_ls} as 
\begin{align*}
\frac{\phi^{n+1}_{ij} - \phi^n_{ij}}{\Delta t} 
&= \abs{D^0 \phi^n}
\left(
D^-_x \left( \frac{g_{ij}D^+_x \phi_{ij}^{n+1}}{\sqrt{ (D^+_x \phi^n_{ij})^2 + (D^0_y \phi^n_{ij})^2 + \varepsilon^2}}
\right) 
+ D^-_y \left(  \frac{g_{ij}D^+_y \phi_{ij}^{n+1}}{\sqrt{ (D^0_x \phi^n_{ij})^2 + (D^+_y \phi^n_{ij})^2  + \varepsilon^2}}
\right)
\right)
\\
&= 
\abs{D^0 \phi^n}\frac{ g_{ij}/h^2 }{\sqrt{ \frac{1}{h^2}(\phi^n_{i+1j} -\phi^n_{ij} )^2 + \frac{1}{4h^2} (\phi^n_{i,j+1} - \phi^n_{i,j-1})^2 + \varepsilon^2}}
(\phi^{n+1}_{i+1,j} - \phi^{n+1}_{ij})
\\
&\quad-\abs{D^0 \phi^n}\frac{ g_{i-1,j}/h^2 }{\sqrt{ \frac{1}{h^2}(\phi^n_{ij} -\phi^n_{i-1,j} )^2 + \frac{1}{4h^2} (\phi^n_{i-1,j+1} - \phi^n_{i-1,j-1})^2 + \varepsilon^2}}
(\phi^{n+1}_{ij} - \phi^{n+1}_{i-1,j}) 
\\
&\quad+\abs{D^0 \phi^n}\frac{ g_{ij}/h^2 }{\sqrt{ \frac{1}{4h^2}(\phi^n_{i+1,j} -\phi^n_{i-1,j} )^2 + \frac{1}{h^2} (\phi^n_{i,j+1} - \phi^n_{ij})^2 + \varepsilon^2}}
(\phi^{n+1}_{i,j+1} - \phi^{n+1}_{ij}) 
\\
&\quad-\abs{D^0 \phi^n}\frac{ g_{i,j-1}/h^2 }{\sqrt{ \frac{1}{4h^2}(\phi^n_{i+1,j-1} -\phi^n_{i-1,j-1} )^2 + \frac{1}{h^2} (\phi^n_{ij} - \phi^n_{i,j-1})^2 + \varepsilon^2}}
(\phi^{n+1}_{ij} - \phi^{n+1}_{i,j-1}) 
\\
&\eqqcolon \abs{D^0 \phi^n} \big[ a_1(\phi^{n+1}_{i+1,j} - \phi^{n+1}_{ij})
- a_2(\phi^{n+1}_{ij} - \phi^{n+1}_{i-1,j}) 
+ a_3(\phi^{n+1}_{i,j+1} - \phi^{n+1}_{ij}) 
- a_4(\phi^{n+1}_{ij} - \phi^{n+1}_{i,j-1})
\big]
\\
&= \abs{D^0 \phi^n} 
\big[ a_1\phi^{n+1}_{i+1,j} 
+ a_2\phi^{n+1}_{i-1,j} 
+ a_3\phi^{n+1}_{i,j+1} 
+ a_4\phi^{n+1}_{i,j-1}
- (a_1 + a_2 + a_3 + a_4) \phi^{n+1}_{ij}
\big].
\end{align*}
Hence 
\begin{align*}
\big[ 
\underbrace{1 + \Delta t\abs{D^0 \phi^n} (a_1 + a_2 + a_3 + a_4) \big]
}_{\eqqcolon a_0} \phi^{n+1}_{ij} 
= \phi^n_{ij} + \Delta t\abs{D^0 \phi^n} (a_1\phi^{n+1}_{i+1,j} 
+ a_2\phi^{n+1}_{i-1,j} 
+ a_3\phi^{n+1}_{i,j+1} 
+ a_4\phi^{n+1}_{i,j-1}).
\end{align*}
The Gauss-Seidel iterations would be (if working through $(i,j)$ in the usual order)
\begin{align*}
\phi^{n+1}_{ij} 
= \frac{1}{a_0} 
\left( \phi^n_{ij} + \Delta t \abs{D^0 \phi^n}
\left( a_1 \phi^n_{i+1,j} + a_2 \phi^{n+1}_{i-1,j} + a_3 \phi^{n}_{i,j+1} + a_4 \phi^{n+1}_{i,j-1}
\right)
\right).
\end{align*}
One final note with regards to this numerical discretization. It is suggested to alternate the discretization of the divergence term, eg. applying $D^+_x$ on the outside and $D^-_x$ inside, and with various combinations with $D^+_y$, $D^-_y$ as well. Our testing shows this alternating reduces asymmetries in our solutions to the GAC model but produces no observable differences with our later segmentation models.


\section{Examples and discussion} 
In this section, parameters are $\Delta t = 0.05$, $h = 1$, and $\varepsilon = 10^{-6}$, unless otherwise stated.
The edge indicator function used is 
\begin{align}
g = \frac{1}{1 + \abs{\nabla \widetilde f}^2 },
\label{eq:edge_indicator}
\end{align}
where $\widetilde f$ is a Gaussian-smoothed version of the image $f$. Modification of the GAC model to include a constant velocity, $c$, in the normal direction, 
\begin{align}
\phi_t 
= \left( g ( c + \kappa) + \nabla g \cdot \frac{\nabla \phi}{\abs{\nabla \phi}} \right) \abs{\nabla \phi}
= 
\abs{\nabla \phi} \Div\left( g \frac{\nabla \phi}{\abs{\nabla \phi}} \right) 
+ cg \abs{\nabla \phi},
\label{eq:gac+c}
\end{align}
and is explored as well. More detail on this below.


Our first series of tests is on a synthetic image with 8 objects (squares) with which we run four scenarios starting from two different initial contours. This is shown in \Cref{fig:grid}. In the top row is the first two scenarios with the initial contour  beinng a single, giant circle. From here we run two cases. With no added constant normal velocity, i.e. $c = 0$, we get a bounding box on our eight squares (top row middle). This is a local minimum and the contour does not drive into the gaps. Supplied with an extra push, i.e. setting $c = -1$, the segmentation algorithm picks out all eight squares (top right).
	
In the second row, we have multiple circles forming the initial contour, with two of the circles enclosing one square each and the centre circle feeling a little empty. Setting $c = 0$ (and $c < 0$), the contours contract, causing the centre circle to vanish and the other two to wrap tightly around their square. Setting $c = 1$, the contours expand, missing two squares.
	
We find the model adheres to edges nicely. Whenever the contour locates an edge, it stays there. However, even in our limited testing it is clear that this method requires significant high level input in at least two ways. First, the ``right'' initial contour is needed to generate the desired result. This may require, for every image, a user having to drawing a rough contour around all objects before letting the algorithm take over. Second would be to specify $c$. Not only does nonzero values of $c$ produce drastically different results from $c = 0$, but it also drove the solution to steady state faster. Without a suitable value of $c$, this method is impractical. In some of our cases, the total number of iterations was reduced by a factor of over $100$.
	
\begin{figure}[htb!]
	\centering
	\begin{minipage}{0.31\textwidth}
				\includegraphics[width=\textwidth]{grid1}
	\end{minipage}\,
	\begin{minipage}{0.31\textwidth}
		\includegraphics[width=\textwidth]{grid1ssc0}
	\end{minipage}\,
	\begin{minipage}{0.31\textwidth}
		\includegraphics[width=\textwidth]{grid1sscm1}
	\end{minipage}
	\begin{minipage}{0.31\textwidth}
		\includegraphics[width=\textwidth]{grid2}
	\end{minipage}\,
	\begin{minipage}{0.31\textwidth}
		\includegraphics[width=\textwidth]{grid2ssc0}
	\end{minipage}\,
	\begin{minipage}{0.31\textwidth}
		\includegraphics[width=\textwidth]{grid2sscp1}
	\end{minipage}
	
	\caption{(Left) Initial setups. (Middle) Steady state solution with $c = 0$. (Top right) Steady state solution with $c = -1$. (Bottom right) Steady state solution with $c = 1$.}
	\label{fig:grid}
\end{figure}

In closing this chapter, we recognize that while one example is by no means a comprehensive study on this model, we have identified a key issues we fully expect the next segmentation models to improve upon, namely sensitivity to the initial condition and reliance on high level input.
	

